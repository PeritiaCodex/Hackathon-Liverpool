{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from vertexai.vision_models import Image, MultiModalEmbeddingModel\n",
        "from google.cloud import bigquery, storage\n",
        "import os\n",
        "\n",
        "# Configura tu proyecto y variables de BigQuery\n",
        "project_id = \"liverpoolsku-439723\"\n",
        "vertexai.init(project=project_id, location=\"us-central1\")\n",
        "\n",
        "# Variables de configuración\n",
        "BUCKET_NAME = \"mi-bucket-de-imagenes1\"\n",
        "DATASET_ID = \"image_dataset\"\n",
        "TABLE_ID = \"image_embeddings\"\n",
        "LOCAL_DOWNLOAD_PATH = \"/tmp\"\n",
        "\n",
        "# Inicializar el cliente de BigQuery y Storage\n",
        "bigquery_client = bigquery.Client(project=project_id)\n",
        "storage_client = storage.Client(project=project_id)\n",
        "\n",
        "# Cargar el modelo de Gemini Vision para embeddings\n",
        "model = MultiModalEmbeddingModel.from_pretrained(\"multimodalembedding\")\n",
        "\n",
        "def generate_and_store_embeddings(bucket_name, dataset_id, table_id):\n",
        "    # Crear el dataset y la tabla en BigQuery si no existen\n",
        "    dataset_ref = bigquery_client.dataset(dataset_id)\n",
        "    table_ref = dataset_ref.table(table_id)\n",
        "\n",
        "    schema = [\n",
        "        bigquery.SchemaField(\"image_uri\", \"STRING\"),\n",
        "        bigquery.SchemaField(\"embedding\", \"FLOAT64\", mode=\"REPEATED\"),\n",
        "    ]\n",
        "    table = bigquery.Table(table_ref, schema=schema)\n",
        "    bigquery_client.create_table(table, exists_ok=True)\n",
        "\n",
        "    # Listar y procesar cada imagen en el bucket\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blobs = bucket.list_blobs()\n",
        "\n",
        "    for blob in blobs:\n",
        "        if blob.name.endswith(('.jpg', '.jpeg', '.png')):  # Filtrar solo imágenes\n",
        "            image_uri = f\"gs://{bucket_name}/{blob.name}\"\n",
        "            print(f\"Procesando imagen: {image_uri}\")\n",
        "\n",
        "            # Descargar la imagen localmente\n",
        "            local_image_path = os.path.join(LOCAL_DOWNLOAD_PATH, blob.name)\n",
        "            blob.download_to_filename(local_image_path)\n",
        "\n",
        "            # Crear objeto de imagen para Vertex AI desde el archivo local\n",
        "            image_part = Image.load_from_file(local_image_path)\n",
        "\n",
        "            # Generar embeddings\n",
        "            image_embedding = model.get_embeddings(\n",
        "                image=image_part,\n",
        "                dimension=128  # Cambiar dimensión según necesidad\n",
        "            ).image_embedding\n",
        "\n",
        "            # Insertar en BigQuery\n",
        "            rows_to_insert = [\n",
        "                {\n",
        "                    \"image_uri\": image_uri,\n",
        "                    \"embedding\": list(image_embedding),  # Convierte el embedding a lista\n",
        "                }\n",
        "            ]\n",
        "            errors = bigquery_client.insert_rows_json(table_ref, rows_to_insert)\n",
        "            if errors:\n",
        "                print(f\"Errores al insertar en BigQuery: {errors}\")\n",
        "            else:\n",
        "                print(f\"Embeddings de {image_uri} almacenados en BigQuery.\")\n",
        "\n",
        "            # Eliminar la imagen local para liberar espacio\n",
        "            os.remove(local_image_path)\n"
      ],
      "metadata": {
        "id": "fSxe2W4K94V5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "import numpy as np\n",
        "\n",
        "# Parámetros de configuración\n",
        "project_id = \"liverpoolsku-439723\"\n",
        "dataset_id = \"image_dataset\"\n",
        "table_id = \"image_embeddings\"\n",
        "bigquery_client = bigquery.Client(project=project_id)\n",
        "\n",
        "def find_similar_images(query_embedding, top_k=5):\n",
        "    # Convertir el embedding a formato adecuado para SQL\n",
        "    embedding_str = \",\".join(map(str, query_embedding))\n",
        "\n",
        "    # Consulta de BigQuery para encontrar las imágenes más similares\n",
        "    query = f\"\"\"\n",
        "    SELECT\n",
        "        image_uri,\n",
        "        SQRT(SUM(POW(embedding_value - query_value, 2))) AS distance\n",
        "    FROM\n",
        "        `{project_id}.{dataset_id}.{table_id}`,\n",
        "        UNNEST(embedding) AS embedding_value WITH OFFSET AS index1,\n",
        "        UNNEST([ARRAY<{len(query_embedding)}>]({embedding_str})) AS query_value WITH OFFSET AS index2\n",
        "    WHERE\n",
        "        index1 = index2\n",
        "    GROUP BY\n",
        "        image_uri\n",
        "    ORDER BY\n",
        "        distance ASC\n",
        "    LIMIT\n",
        "        {top_k}\n",
        "    \"\"\"\n",
        "\n",
        "    # Ejecutar la consulta\n",
        "    query_job = bigquery_client.query(query)\n",
        "    results = query_job.result()\n"
      ],
      "metadata": {
        "id": "y03u0S-OECsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install torch torchvision google-cloud-bigquery google-cloud-storage\n",
        "\n",
        "# Import necessary libraries\n",
        "from google.colab import files\n",
        "from google.cloud import storage, bigquery\n",
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Upload your JSON credentials\n",
        "uploaded_credentials = files.upload()  # Upload credentials file\n",
        "credentials_file = list(uploaded_credentials.keys())[0]\n",
        "\n",
        "# Set up authentication\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credentials_file\n",
        "\n",
        "# Step 2: Upload the image file\n",
        "uploaded_image = files.upload()  # Upload image to GCS\n",
        "local_image_path = list(uploaded_image.keys())[0]\n",
        "\n",
        "# Step 3: Configure bucket and file name\n",
        "BUCKET_NAME = \"mi-bucket-de-imagenes1\"\n",
        "REMOTE_FILE_NAME = \"nombre_en_gcs.jpg\"  # Set remote GCS name\n",
        "\n",
        "# Function to upload file to GCS\n",
        "def upload_single_file_to_gcs(bucket_name, local_file_path, remote_file_name):\n",
        "    storage_client = storage.Client()  # Use default credentials\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(remote_file_name)\n",
        "    blob.upload_from_filename(local_file_path)\n",
        "    print(f\"File '{local_file_path}' uploaded to '{bucket_name}/{remote_file_name}'.\")\n",
        "\n",
        "# Upload the image\n",
        "upload_single_file_to_gcs(BUCKET_NAME, local_image_path, REMOTE_FILE_NAME)\n",
        "\n",
        "# Load a pre-trained model (e.g., ResNet-50) for embeddings\n",
        "model = models.resnet50(pretrained=True)\n",
        "model = torch.nn.Sequential(*list(model.children())[:-1])  # Remove last layer for embeddings\n",
        "model.eval()\n",
        "\n",
        "# Define the preprocessing transformation\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load and preprocess the image\n",
        "input_image = Image.open(local_image_path).convert(\"RGB\")  # Ensure image is in RGB mode\n",
        "input_tensor = preprocess(input_image)\n",
        "input_batch = input_tensor.unsqueeze(0)  # Create mini-batch\n",
        "\n",
        "# Generate the embedding\n",
        "with torch.no_grad():\n",
        "    embedding = model(input_batch).flatten().numpy()\n",
        "\n",
        "# Convert the embedding into a list format\n",
        "embedding_list = embedding.tolist()\n",
        "\n",
        "# Insert the embedding into BigQuery\n",
        "table_id = \"liverpoolsku-439723.image_dataset.image_embeddings\"  # Replace with your table ID\n",
        "client = bigquery.Client()\n",
        "rows_to_insert = [{\"image_path\": local_image_path, \"embedding\": embedding_list}]\n",
        "errors = client.insert_rows_json(table_id, rows_to_insert)\n",
        "\n",
        "if errors:\n",
        "    print(\"Failed to insert rows:\", errors)\n",
        "else:\n",
        "    print(\"Embedding successfully uploaded.\")\n",
        "\n",
        "# Function to find similar images in BigQuery based on embeddings\n",
        "def find_similar_images(embedding, threshold=0.85):\n",
        "    query_embedding_str = ', '.join([str(x) for x in embedding])  # Embed as string for SQL\n",
        "\n",
        "    query = f\"\"\"\n",
        "    WITH similarity_calculation AS (\n",
        "        SELECT\n",
        "            image_path,\n",
        "            (\n",
        "                SUM(value * embedding[SAFE_OFFSET(off)])  # Correct usage of SAFE_OFFSET\n",
        "                /\n",
        "                (\n",
        "                    SQRT(SUM(embedding[SAFE_OFFSET(off)] * embedding[SAFE_OFFSET(off)]))\n",
        "                    * SQRT(SUM(value * value))\n",
        "                )\n",
        "            ) AS similarity\n",
        "        FROM\n",
        "            `liverpoolsku-439723.image_dataset.image_embeddings`,\n",
        "            UNNEST(ARRAY[{query_embedding_str}]) AS value WITH OFFSET off\n",
        "        GROUP BY image_path\n",
        "    )\n",
        "    SELECT *\n",
        "    FROM similarity_calculation\n",
        "    WHERE similarity >= {threshold}\n",
        "    ORDER BY similarity DESC\n",
        "    LIMIT 10\n",
        "    \"\"\"\n",
        "\n",
        "    query_job = client.query(query)\n",
        "    results = query_job.result()\n",
        "    return results.to_dataframe()\n",
        "\n",
        "# Find and display similar images\n",
        "similar_images = find_similar_images(embedding)\n",
        "print(\"Similar images found:\")\n",
        "print(similar_images)\n"
      ],
      "metadata": {
        "id": "DjlLswXvFBFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install torch torchvision google-cloud-storage google-cloud-bigquery\n",
        "\n",
        "# Import necessary libraries\n",
        "from google.cloud import storage\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Step 1: Set the path to your credentials JSON file\n",
        "# Update the path to the actual location of your JSON credentials file\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/liverpoolsku-439723-53590f1899b6.json\"\n",
        "\n",
        "# Step 2: Define the path of the local image you want to compare\n",
        "local_image_path = \"/content/imagen_2024-10-26_051110742.png\"  # Replace with the actual image path\n",
        "\n",
        "# Step 3: Configure bucket and file name\n",
        "BUCKET_NAME = \"mi-bucket-de-imagenes1\"\n",
        "REMOTE_FILE_NAME = \"nombre_en_gcs.jpg\"  # Set remote GCS name\n",
        "\n",
        "# Upload the image to GCS\n",
        "def upload_single_file_to_gcs(bucket_name, local_file_path, remote_file_name):\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(remote_file_name)\n",
        "    blob.upload_from_filename(local_file_path)\n",
        "    print(f\"File '{local_file_path}' uploaded to '{bucket_name}/{remote_file_name}'.\")\n",
        "\n",
        "upload_single_file_to_gcs(BUCKET_NAME, local_image_path, REMOTE_FILE_NAME)\n",
        "\n",
        "# Load a pretrained model (e.g., ResNet-50) for generating embeddings\n",
        "model = models.resnet50(pretrained=True)\n",
        "model = torch.nn.Sequential(*list(model.children())[:-1])  # Remove last layer for embeddings\n",
        "model.eval()\n",
        "\n",
        "# Define preprocessing transformation\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Preprocess and generate the embedding for the uploaded image\n",
        "input_image = Image.open(local_image_path).convert(\"RGB\")\n",
        "input_tensor = preprocess(input_image)\n",
        "input_batch = input_tensor.unsqueeze(0)\n",
        "\n",
        "with torch.no_grad():\n",
        "    query_embedding = model(input_batch).flatten().numpy()\n",
        "\n",
        "# Function to download embeddings from GCS bucket\n",
        "def get_embeddings_from_gcs(bucket_name):\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blobs = bucket.list_blobs()\n",
        "\n",
        "    embeddings = []\n",
        "    image_paths = []\n",
        "\n",
        "    for blob in blobs:\n",
        "        if blob.name.endswith('.npy'):  # Assuming embeddings are saved as .npy files\n",
        "            blob.download_to_filename('/tmp/' + blob.name)\n",
        "            embedding = np.load('/tmp/' + blob.name)\n",
        "            embeddings.append(embedding)\n",
        "            image_paths.append(blob.name.replace('.npy', ''))\n",
        "\n",
        "    return image_paths, embeddings\n",
        "\n",
        "# Retrieve stored embeddings from GCS\n",
        "image_paths, stored_embeddings = get_embeddings_from_gcs(BUCKET_NAME)\n",
        "\n",
        "# Calculate cosine similarity\n",
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "# Find similar images\n",
        "def find_similar_images(query_embedding, stored_embeddings, image_paths, threshold=0.85):\n",
        "    similarities = []\n",
        "    for image_path, embedding in zip(image_paths, stored_embeddings):\n",
        "        similarity = cosine_similarity(query_embedding, embedding)\n",
        "        if similarity >= threshold:\n",
        "            similarities.append((image_path, similarity))\n",
        "\n",
        "    # Sort by similarity\n",
        "    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
        "    return similarities[:10]\n",
        "\n",
        "# Find and display similar images\n",
        "similar_images = find_similar_images(query_embedding, stored_embeddings, image_paths)\n",
        "print(\"Similar images found:\")\n",
        "for img_path, sim in similar_images:\n",
        "    print(f\"Image: {img_path}, Similarity: {sim}\")"
      ],
      "metadata": {
        "id": "uKWFF-39jwB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install google-cloud-storage torch torchvision numpy\n",
        "\n",
        "# Import required libraries\n",
        "from google.cloud import storage\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Initialize GCS client\n",
        "storage_client = storage.Client()\n",
        "bucket_name = \"mi-bucket-de-imagenes1\"  # Change to your bucket name\n",
        "bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "# Load a pre-trained model (ResNet-50) and remove the last layer to get embeddings\n",
        "model = models.resnet50(pretrained=True)\n",
        "model = torch.nn.Sequential(*list(model.children())[:-1])  # Remove the classification layer\n",
        "model.eval()\n",
        "\n",
        "# Define image transformations\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Function to convert an image to embedding\n",
        "def image_to_embedding(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    input_tensor = preprocess(image)\n",
        "    input_batch = input_tensor.unsqueeze(0)  # Create mini-batch as expected by model\n",
        "\n",
        "    with torch.no_grad():\n",
        "        embedding = model(input_batch).flatten().numpy()\n",
        "    return embedding\n",
        "\n",
        "# Function to process each image in the GCS bucket\n",
        "def process_images_and_save_embeddings():\n",
        "    for blob in bucket.list_blobs():\n",
        "        if blob.name.endswith(\".jpg\") or blob.name.endswith(\".png\"):  # Process only image files\n",
        "            # Download the image file temporarily\n",
        "            temp_image_path = \"/tmp/\" + blob.name.split(\"/\")[-1]\n",
        "            blob.download_to_filename(temp_image_path)\n",
        "\n",
        "            # Generate embedding\n",
        "            embedding = image_to_embedding(temp_image_path)\n",
        "\n",
        "            # Save the embedding as a .npy file locally\n",
        "            temp_npy_path = temp_image_path.split(\".\")[0] + \".npy\"\n",
        "            np.save(temp_npy_path, embedding)\n",
        "\n",
        "            # Upload the .npy file to the GCS bucket with an \"embeddings/\" prefix\n",
        "            npy_blob_name = \"embeddings/\" + os.path.basename(temp_npy_path)\n",
        "            npy_blob = bucket.blob(npy_blob_name)\n",
        "            npy_blob.upload_from_filename(temp_npy_path)\n",
        "\n",
        "            print(f\"Processed and uploaded embedding for {blob.name} as {npy_blob_name}\")\n",
        "\n",
        "# Run the function to process images and save embeddings\n",
        "process_images_and_save_embeddings()\n"
      ],
      "metadata": {
        "id": "M59uAwjlkU3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries if not installed\n",
        "!pip install torch torchvision google-cloud-storage scikit-learn\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "from google.cloud import storage\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Initialize Google Cloud Storage client\n",
        "storage_client = storage.Client()\n",
        "bucket_name = \"mi-bucket-de-imagenes1\"  # Replace with your actual bucket name\n",
        "bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "# Load a pre-trained model (e.g., ResNet-50) and remove the last layer for embedding extraction\n",
        "model = models.resnet50(pretrained=True)\n",
        "model = torch.nn.Sequential(*list(model.children())[:-1])\n",
        "model.eval()\n",
        "\n",
        "# Define transformations for preprocessing\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Function to generate embedding for an image\n",
        "def generate_embedding(image_path):\n",
        "    input_image = Image.open(image_path)\n",
        "\n",
        "    # Convert RGBA to RGB if needed\n",
        "    if input_image.mode == 'RGBA':\n",
        "        input_image = input_image.convert('RGB')\n",
        "\n",
        "    input_tensor = preprocess(input_image)\n",
        "    input_batch = input_tensor.unsqueeze(0)  # Create a mini-batch as expected by the model\n",
        "\n",
        "    # Generate the embedding\n",
        "    with torch.no_grad():\n",
        "        embedding = model(input_batch).flatten().numpy()\n",
        "    return embedding\n",
        "\n",
        "# Path to the uploaded image\n",
        "uploaded_image_path = \"/content/imagen_2024-10-26_051110742.png\"  # Replace with actual image path\n",
        "new_image_embedding = generate_embedding(uploaded_image_path)\n",
        "\n",
        "# Function to load a .npy embedding file from GCS\n",
        "def load_embedding_from_gcs(npy_file_name):\n",
        "    npy_blob = bucket.blob(npy_file_name)\n",
        "    temp_npy_path = \"/tmp/\" + os.path.basename(npy_file_name)\n",
        "    npy_blob.download_to_filename(temp_npy_path)\n",
        "    embedding = np.load(temp_npy_path)\n",
        "    return embedding\n",
        "\n",
        "# List all .npy embedding files in the bucket\n",
        "embedding_files = [blob.name for blob in bucket.list_blobs(prefix=\"embeddings/\") if blob.name.endswith('.npy')]\n",
        "\n",
        "# Load all embeddings from the bucket\n",
        "stored_embeddings = []\n",
        "file_names = []\n",
        "\n",
        "for npy_file in embedding_files:\n",
        "    embedding = load_embedding_from_gcs(npy_file)\n",
        "    stored_embeddings.append(embedding)\n",
        "    file_names.append(npy_file)  # Keep track of file names for reference\n",
        "\n",
        "# Compute cosine similarity between new image embedding and stored embeddings\n",
        "new_image_embedding = new_image_embedding.reshape(1, -1)  # Reshape for cosine similarity calculation\n",
        "similarities = []\n",
        "\n",
        "for idx, stored_embedding in enumerate(stored_embeddings):\n",
        "    stored_embedding = stored_embedding.reshape(1, -1)  # Ensure it's 2D\n",
        "    similarity = cosine_similarity(new_image_embedding, stored_embedding)[0][0]\n",
        "    similarities.append((file_names[idx], similarity))\n",
        "\n",
        "# Sort by similarity in descending order\n",
        "similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Display the most similar images\n",
        "top_n = 5  # Number of top similar images to display\n",
        "print(\"Top similar images:\")\n",
        "for file_name, similarity_score in similarities[:top_n]:\n",
        "    print(f\"{file_name}: Similarity = {similarity_score:.4f}\")\n"
      ],
      "metadata": {
        "id": "oVTNdArbppAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# Define bucket URL format for images\n",
        "bucket_url = \"https://storage.googleapis.com/mi-bucket-de-imagenes1/\"\n",
        "\n",
        "# Display top similar images using URLs\n",
        "top_n = 5\n",
        "print(\"Top similar images:\")\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "for i, (file_name, similarity_score) in enumerate(similarities[:top_n]):\n",
        "    # Construct URL based on file name\n",
        "    image_name = file_name.replace(\"embeddings/\", \"\").replace(\".npy\", \".jpg\")\n",
        "    image_url = f\"{bucket_url}{image_name}\"\n",
        "\n",
        "    print(f\"{image_name}: Similarity = {similarity_score:.4f} | URL: {image_url}\")\n",
        "\n",
        "    # Fetch and display the image from the URL\n",
        "    try:\n",
        "        response = requests.get(image_url)\n",
        "        response.raise_for_status()  # Check if the request was successful\n",
        "        img = Image.open(BytesIO(response.content))\n",
        "\n",
        "        plt.subplot(1, top_n, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Sim: {similarity_score:.2f}\")\n",
        "        plt.axis('off')\n",
        "    except Exception as e:\n",
        "        print(f\"Could not load image from {image_url}. Error: {e}\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I5y9ewc4uUxD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}